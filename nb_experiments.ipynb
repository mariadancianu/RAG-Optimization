{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b0accd0d-fb0b-4c5e-be02-8063d3b6a2c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mariadancianu/Desktop/Git Projects/RAG-Optimization/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "import os \n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.auto import tqdm\n",
    "from rag_optimization import convert_knowledge_base_to_langchain_docs, optimize_rag_parameters\n",
    "from data_utils import convert_json_to_dataframe, create_json_subset, collect_all_results, merge_results\n",
    "sns.set_style(\"whitegrid\")\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "953814b1",
   "metadata": {},
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ece24fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Useful material \n",
    "# SQuAD Evaluation guidelines: \n",
    "# https://worksheets.codalab.org/worksheets/0x8212d84ca41c4150b555a075b19ccc05/\n",
    "# https://rajpurkar.github.io/SQuAD-explorer/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "868b749b",
   "metadata": {},
   "source": [
    "# Convert json data to pandas dataframe "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f49d8df1-cea0-410b-9c27-985406ea208b",
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_json_to_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2a6d356",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_data = pd.read_csv(\"dataset.csv\")\n",
    "df_all_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5771778e-ae9e-49b4-9216-658bdefc8db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_selected = df_all_data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81f2eebd-70b9-4118-b691-0c6c96e72a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# some rough statistics for the context length \n",
    "df_selected.loc[:, \"context_chars\"] = df_selected[\"context\"].apply(lambda x: len(x))\n",
    "df_selected.loc[:, \"context_words\"] = df_selected.loc[:, \"context\"].apply(lambda x: len(x.split(\" \")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80f66f8e-3eb9-4943-9b2e-40df68068a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_selected.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8cab993-b3ab-4947-acb5-016382d1321b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=[8, 5])\n",
    "sns.histplot(df_selected.drop_duplicates(subset=\"context\")[\"context_chars\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cfb1095-e0d8-4f06-b203-08ff1689aeaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=[8, 5])\n",
    "sns.histplot(df_selected.drop_duplicates(subset=\"context\")[\"context_words\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a9848fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create original json structure for only a subset of questions, used for tests and fine-tuning \n",
    "# this file will be used by the evaluation.py file \n",
    "\n",
    "df = pd.read_csv(\"dataset.csv\")\n",
    "df_sel = df[0:500]\n",
    "df_sel.head(2)\n",
    "\n",
    "create_json_subset(df_sel)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef7c8057-750e-44d6-81c8-d8ad6717b311",
   "metadata": {},
   "source": [
    "# RAG architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8caf8664-3381-4701-b297-bbcfa5176872",
   "metadata": {},
   "source": [
    "Steps:\n",
    "\n",
    "**Data Indexing**\n",
    "\n",
    "Converting text data into a searchable database of vector embeddings, which represent the meaning of the text in a format that computers can easily understand.\n",
    "- **Documents Chunking**: The collection of documents is split into smaller chunks of text. This allows for more precise and relevant pieces of information to be fed into the language model when needed, avoiding information overload.\n",
    "- **Vector Embeddings**: The chunks of text are then transformed into vector embeddings. These embeddings encode the meaning of natural language text into numerical representations.\n",
    "- **Vector Database**: Finally, the vector embeddings are stored in a vector database, making them easily searchable.\n",
    "\n",
    "**Documents -> Text chunks -> Vector Embeddings -> Vector DB**\n",
    "\n",
    "**Load -> Split -> Embed -> Store**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9dfc599",
   "metadata": {},
   "source": [
    "## Convert the pandas context to Langchain documents "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "957f241f-d54c-452e-94ad-cfcc8a81a836",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"dataset.csv\")\n",
    "\n",
    "langchain_docs = convert_knowledge_base_to_langchain_docs(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46d8e92a-9322-4359-b18b-f4217fb78003",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(langchain_docs))\n",
    "print(langchain_docs[0])\n",
    "print(langchain_docs[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2075d54",
   "metadata": {},
   "source": [
    "## Vector database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de25a07e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rag_optimization import CustomRAG, prompt_message, convert_knowledge_base_to_langchain_docs\n",
    "\n",
    "parameters_dict = {\n",
    "    \"chunk_size\": 400,\n",
    "    \"chunk_overlap\": 15,\n",
    "    \"vector_database\": \"chromadb\",\n",
    "    \"embeddings_function\": {\n",
    "        \"model_name\": \"text-embedding-3-large\",    \n",
    "        \"platform\": \"OpenAI\"\n",
    "        }, \n",
    "    \"llm\": {\n",
    "        \"model_name\": \"gpt-3.5-turbo\",\n",
    "        \"client\": \"OpenAI\"\n",
    "        }\n",
    "}\n",
    "\n",
    "df_to_test = df[0:10]\n",
    "\n",
    "rag = CustomRAG(knowledge_base=langchain_docs, \n",
    "                prompt_message=prompt_message,\n",
    "                config=parameters_dict, \n",
    "                results_folder='/eval_results/test_new_class', \n",
    "                vector_db_folder='/vector_databases/test_new_class')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d08f77e",
   "metadata": {},
   "outputs": [],
   "source": [
    "rag.initialize_embeddings_function()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e9878b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_model = \"text-embedding-3-small\"\n",
    "embeddings = OpenAIEmbeddings(model=embeddings_model)\n",
    "\n",
    "db_dir = os.path.join(os.getcwd(), \"vector_databases\")\n",
    "\n",
    "rag.create_vector_database()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0571139",
   "metadata": {},
   "source": [
    "## Querying the vector database "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20c5fcd1-6677-4a48-823c-7b899bfee9fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"How is the weather today in Milan?\"\n",
    "relevant_docs = rag.query_vector_store(query, n_results=3, score_threshold=0.1)\n",
    "\n",
    "print(relevant_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d473dd71",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Who were the normans?\"\n",
    "relevant_docs = rag.query_vector_store(query, n_results=3, score_threshold=0.1)\n",
    "\n",
    "print(len(relevant_docs))\n",
    "\n",
    "for doc in relevant_docs:\n",
    "    print(doc.page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e5aa673",
   "metadata": {},
   "source": [
    "## Run the RAG over a subset of questions and save the answers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb0a1187",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_to_test = pd.read_csv(\"dataset.csv\")\n",
    "df_to_test = df_to_test[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff098d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "rag.get_llm_multiple_questions_answers(df_to_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b204b4fa",
   "metadata": {},
   "source": [
    "## RAG Fine-tuning "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "273535f0",
   "metadata": {},
   "source": [
    "TEXT CHUNKING \n",
    "\n",
    "1. CHARACTER SPLITTING : divide the text into N-character sized chunks. Can split words in the middle. \n",
    "2. RECURSIVE CHARACTER SPLITTING: preserves sentences. Avoids splitting sentences midword (note that RecursiveCharacterTextSplitter with separator does exactly that). Split the\n",
    "document where a double new line is present, then, if the chunk size is still exceeded, split at new lines, and so on.\n",
    "3. SEMANTIC SPLITTING: keeps related content together. Use embeddings to split based on meaning.\n",
    "+ other techniques\n",
    "\n",
    "EMBEDDINGS \n",
    "Create fixed-length vector representation of text, focusing on semanting meaning for tasks like similarity comparison. \n",
    "Most up to date embedding models, both proprietary and open source, with performance metrics across different tasks: https://huggingface.co/spaces/mteb/leaderboard.\n",
    "\n",
    "This contains also a \"retrieval\" column with performance metrics. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0830832",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"dataset.csv\")\n",
    "df_to_test = df[0:500]\n",
    "\n",
    "langchain_docs = convert_knowledge_base_to_langchain_docs(df)\n",
    "\n",
    "optimize_rag_parameters(\n",
    "    df_to_test, \n",
    "    langchain_docs, \n",
    "    results_folder=\"eval_results/test_new_class\", \n",
    "    vector_db_folder=\"vector_databases/test_new_class\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d407aed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"eval_results/test_new_class\"\n",
    "df_all_res = collect_all_results(path)\n",
    "df_all_res.sort_values(by=\"HasAns_f1\", ascending=False, inplace=True)\n",
    "df_all_res.to_csv(f\"{path}/df_all_results.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f78f94bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>exact</th>\n",
       "      <th>f1</th>\n",
       "      <th>total</th>\n",
       "      <th>HasAns_exact</th>\n",
       "      <th>HasAns_f1</th>\n",
       "      <th>HasAns_total</th>\n",
       "      <th>NoAns_exact</th>\n",
       "      <th>NoAns_f1</th>\n",
       "      <th>NoAns_total</th>\n",
       "      <th>experiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>49.6</td>\n",
       "      <td>54.188264</td>\n",
       "      <td>500</td>\n",
       "      <td>61.603376</td>\n",
       "      <td>71.283257</td>\n",
       "      <td>237</td>\n",
       "      <td>38.783270</td>\n",
       "      <td>38.783270</td>\n",
       "      <td>263</td>\n",
       "      <td>eval_pred_400_text-embedding-3-small_gpt-3.5-t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>50.0</td>\n",
       "      <td>55.196172</td>\n",
       "      <td>500</td>\n",
       "      <td>59.493671</td>\n",
       "      <td>70.456060</td>\n",
       "      <td>237</td>\n",
       "      <td>41.444867</td>\n",
       "      <td>41.444867</td>\n",
       "      <td>263</td>\n",
       "      <td>eval_pred_200_text-embedding-3-small_gpt-3.5-t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>44.6</td>\n",
       "      <td>49.323149</td>\n",
       "      <td>500</td>\n",
       "      <td>59.493671</td>\n",
       "      <td>69.458120</td>\n",
       "      <td>237</td>\n",
       "      <td>31.178707</td>\n",
       "      <td>31.178707</td>\n",
       "      <td>263</td>\n",
       "      <td>eval_pred_500_text-embedding-3-small_gpt-3.5-t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>43.4</td>\n",
       "      <td>48.797472</td>\n",
       "      <td>500</td>\n",
       "      <td>56.962025</td>\n",
       "      <td>68.349097</td>\n",
       "      <td>237</td>\n",
       "      <td>31.178707</td>\n",
       "      <td>31.178707</td>\n",
       "      <td>263</td>\n",
       "      <td>eval_pred_600_text-embedding-3-small_gpt-3.5-t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50.6</td>\n",
       "      <td>54.960261</td>\n",
       "      <td>500</td>\n",
       "      <td>46.413502</td>\n",
       "      <td>55.612365</td>\n",
       "      <td>237</td>\n",
       "      <td>54.372624</td>\n",
       "      <td>54.372624</td>\n",
       "      <td>263</td>\n",
       "      <td>eval_pred_100_text-embedding-3-small_gpt-3.5-t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   exact         f1  total  HasAns_exact  HasAns_f1  HasAns_total  \\\n",
       "3   49.6  54.188264    500     61.603376  71.283257           237   \n",
       "2   50.0  55.196172    500     59.493671  70.456060           237   \n",
       "1   44.6  49.323149    500     59.493671  69.458120           237   \n",
       "0   43.4  48.797472    500     56.962025  68.349097           237   \n",
       "4   50.6  54.960261    500     46.413502  55.612365           237   \n",
       "\n",
       "   NoAns_exact   NoAns_f1  NoAns_total  \\\n",
       "3    38.783270  38.783270          263   \n",
       "2    41.444867  41.444867          263   \n",
       "1    31.178707  31.178707          263   \n",
       "0    31.178707  31.178707          263   \n",
       "4    54.372624  54.372624          263   \n",
       "\n",
       "                                          experiment  \n",
       "3  eval_pred_400_text-embedding-3-small_gpt-3.5-t...  \n",
       "2  eval_pred_200_text-embedding-3-small_gpt-3.5-t...  \n",
       "1  eval_pred_500_text-embedding-3-small_gpt-3.5-t...  \n",
       "0  eval_pred_600_text-embedding-3-small_gpt-3.5-t...  \n",
       "4  eval_pred_100_text-embedding-3-small_gpt-3.5-t...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all_res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c923406",
   "metadata": {},
   "source": [
    "# Investigate the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "008528cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick the best results and merge the scores by question id to the original df in order to inspect the errors.\n",
    "# The idea is to understand why the results are so poor for the NoAns questions, when the HasAns questions have \n",
    "# a high f1 score, in order to understand how the workflow can be optimized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aeaa4a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_result_path = os.path.join(os.getcwd(), \"eval_results/initial_eval_results\", df_all_res.experiment.iloc[0])\n",
    "split_path = best_result_path.split(\"/\")\n",
    "split_path[-1] = split_path[-1].replace(\"eval_\", \"\")\n",
    "best_result_path = \"/\".join(split_path)\n",
    "best_result_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1beec24",
   "metadata": {},
   "outputs": [],
   "source": [
    "! python $(pwd)/eval_results/evaluation.py \"$(pwd)/eval_results/data_updated_500.json\" \"$(pwd)/eval_results/debugging_eval_results/pred_500_400_text-embedding-3-large_gpt-3.5-turbo.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44cd3a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged = merge_results(f1_filepath=os.path.join(os.getcwd(), \"eval_results/debugging_eval_results/f1_thresh_by_qid.json\"), \n",
    "                          exact_filepath=os.path.join(os.getcwd(), \"eval_results/debugging_eval_results/exact_thresh_by_qid.json\"), \n",
    "                          pred_filepath=os.path.join(os.getcwd(), \"eval_results/debugging_eval_results/pred_500_400_text-embedding-3-large_gpt-3.5-turbo.json\"), \n",
    "                          filepath_500=os.path.join(os.getcwd(), \"eval_results/debugging_eval_results/pred_500_400_text-embedding-3-large_gpt-3.5-turbo.json\"),\n",
    "                          context_filepath=os.path.join(os.getcwd(), \"eval_results/debugging_eval_results/context_500_400_text-embedding-3-large_gpt-3.5-turbo.json\"), \n",
    "                          df_questions_filepath=\"dataset.csv\", \n",
    "                          filter_500=True)\n",
    "\n",
    "df_merged.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "585095c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e9391a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged[df_merged.is_impossible][[\"id\", \"is_impossible\", \"f1_score\", \"exact_score\", \"question\", \"pred\"]].tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf1c16c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_merged.loc[479, \"context\"].replace(\". \", \".\\n\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91da5f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_merged.loc[479, \"rag_retrieved_context\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44cef210",
   "metadata": {},
   "source": [
    "# Evaluate with other LLMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e53f063",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine tuning RAG with the following parameters: \n",
      "{'chunk_sizes': [400],\n",
      " 'embed_options': {'text-embedding-3-small': 'OpenAI'},\n",
      " 'models': {'meta/meta-llama-3-70b-instruct': 'Replicate'}}\n",
      "Running meta/meta-llama-3-70b-instruct - 400 - text-embedding-3-small\n",
      "(\"CustomRAG config: {'chunk_size': 400, 'chunk_overlap': 15, \"\n",
      " \"'vector_database': 'chromadb', 'embeddings_function': {'model_name': \"\n",
      " \"'text-embedding-3-small', 'platform': 'OpenAI'}, 'llm': {'model_name': \"\n",
      " \"'meta/meta-llama-3-70b-instruct', 'client': 'Replicate'}}\")\n",
      "Creating vector store 400_text-embedding-3-small\n",
      "Finished creating vector store 400_text-embedding-3-small\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 3/500 [00:03<10:24,  1.26s/it]"
     ]
    }
   ],
   "source": [
    "# run the RAG with best parameters, and save also the context\n",
    "parameters_dict = {\n",
    "    \"chunk_sizes\": [400],\n",
    "    \"embed_options\": { \n",
    "        \"text-embedding-3-small\": \"OpenAI\", \n",
    "        },\n",
    "    \"models\": {\"meta/meta-llama-3-70b-instruct\": \"Replicate\"}\n",
    "}\n",
    "\n",
    "results_folder = os.path.join(os.getcwd(), \"eval_results/optimize_results\")\n",
    "vector_db_folder = os.path.join(os.getcwd(), \"vector_databases\")\n",
    "\n",
    "if not os.path.exists(results_folder):\n",
    "    os.mkdir(results_folder)\n",
    "\n",
    "df = pd.read_csv(\"dataset.csv\")\n",
    "df_to_test = df[0:500]\n",
    "\n",
    "langchain_docs = convert_knowledge_base_to_langchain_docs(df)\n",
    "\n",
    "optimize_rag_parameters(\n",
    "    df_to_test, \n",
    "    langchain_docs, \n",
    "    parameters_dict,\n",
    "    results_folder=results_folder, \n",
    "    vector_db_folder=vector_db_folder\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "765bcaf5",
   "metadata": {},
   "source": [
    "# Evaluate RAG SOTA embeddings: snowflake-artic-embed-l-v2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb576fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# very slow - likely due to GPU/CPU memory issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae2faae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the RAG with SOTA embeddings \n",
    "parameters_dict = {\n",
    "    \"chunk_sizes\": [400],\n",
    "    \"embed_options\": { \n",
    "        \"Snowflake/snowflake-arctic-embed-l-v2.0\": \"SentenceTransformers\" # ranked 6th, 568M params, released in december 2024 \n",
    "        },\n",
    "    \"models\": {\"gpt-3.5-turbo\": \"OpenAI\"}\n",
    "}\n",
    "\n",
    "results_folder = os.path.join(os.getcwd(), \"eval_results/optimize_results\")\n",
    "vector_db_folder = os.path.join(os.getcwd(), \"vector_databases/optimize_results\")\n",
    "\n",
    "if not os.path.exists(results_folder):\n",
    "    os.mkdir(results_folder)\n",
    "\n",
    "df = pd.read_csv(\"dataset.csv\")\n",
    "df_to_test = df[0:500]\n",
    "\n",
    "langchain_docs = convert_knowledge_base_to_langchain_docs(df)\n",
    "\n",
    "optimize_rag_parameters(\n",
    "    df_to_test, \n",
    "    langchain_docs, \n",
    "    parameters_dict,\n",
    "    results_fodler=results_folder, \n",
    "    vector_db_folder=vector_db_folder\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "344d8d63",
   "metadata": {},
   "source": [
    "# Explore replicate "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f2f6a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# allows to run generative AI models in the Cloud \n",
    "# Claude-3-5-sonnet is the best llm for short context (less than 5k tokens) according to this research: https://www.galileo.ai/blog/best-llms-for-rag\n",
    "# the second one is llama-3-70b-instruct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6638f69b",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_system_prompt = f\"\"\"\n",
    "You are a highly accurate and reliable assistant. Answer the user's question using **only** the provided context.\n",
    "If the answer is not in the context, return an empty response (**\"\"**) without making up information.\n",
    "\n",
    "Context:\n",
    "%s\n",
    "\n",
    "Instructions:\n",
    "- Answer concisely and precisely.\n",
    "- If the answer is explicitly stated in the context, extract it as-is.\n",
    "- If the answer is not in the context, return **\"\"** (empty string).\n",
    "- Do **not** infer, assume, or add external information.\n",
    "\n",
    "Example:\n",
    "    **Question:** What is the capital of Italy?\n",
    "    **Answer:** Rome\n",
    "\n",
    "Question: %s\n",
    "Answer (just the answer, no extra words, or \"\" if unknown):\n",
    "\"\"\"\n",
    "\n",
    "query = \"Who were the normans?\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b25697d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import replicate\n",
    "\n",
    "output = replicate.run(\n",
    "   # \"anthropic/claude-3.5-sonnet\", \n",
    "   \"meta/meta-llama-3-70b-instruct\",\n",
    "    input={\n",
    "    \"prompt\": query,\n",
    "    \"system_prompt\": custom_system_prompt,\n",
    "    \"max_tokens\": 512,\n",
    "    \"prompt_template\": \"<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\n{system_prompt}<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\n{prompt}<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n\".format(system_prompt=custom_system_prompt, prompt=\"{prompt}\"),})\n",
    "\n",
    "output_merged = \"\".join(s for s in output if s not in ['\\n', '\\t', '\\r', '\"\"'])\n",
    "output_merged"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
